import express from "express";
import fetch from "node-fetch";
import cors from "cors";

const app = express();
app.use(cors());
app.use(express.json());

app.post("/ask", async (req, res) => {
  try {
    const { message } = req.body;
    if (!message || message.trim() === "") {
      return res.status(400).json({ error: "Message vide" });
    }

    // ðŸ§  Ã‰tape 1 â€” DÃ©terminer si l'IA peut rÃ©pondre ou non
    const moderationPrompt = `
Tu es un assistant Campus France.
Analyse uniquement le contenu du message suivant : "${message}"

Si câ€™est une question gÃ©nÃ©rale (ex: procÃ©dure, visa, documents, frais, dÃ©lais, rendez-vous),
rÃ©ponds exactement par : IA_OK

Sinon, si câ€™est une question personnelle (ex: dossier individuel, compte bloquÃ©, paiement, problÃ¨me technique, retard...),
rÃ©ponds exactement par : AGENT

Ne donne aucune autre rÃ©ponse.
`;

    const modResponse = await fetch("https://api.groq.com/openai/v1/chat/completions", {
      method: "POST",
      headers: {
        "Authorization": `Bearer ${process.env.GROQ_API_KEY}`,
        "Content-Type": "application/json",
      },
      body: JSON.stringify({
        model: "llama-3.3-70b-versatile",
        messages: [{ role: "user", content: moderationPrompt }],
        temperature: 0.1,
      }),
    });

    const modData = await modResponse.json();
    const decision = modData.choices?.[0]?.message?.content?.trim() || "IA_OK";

    // ðŸš§ Ã‰tape 2 â€” Si câ€™est un cas agent
    if (decision === "AGENT") {
      return res.json({
        response:
          "ðŸ“© Votre demande semble spÃ©cifique Ã  votre dossier.\nElle a Ã©tÃ© transmise Ã  un **agent Campus France** qui vous rÃ©pondra sous peu.",
        redirect: true,
      });
    }

    // ðŸ¤– Ã‰tape 3 â€” RÃ©ponse IA naturelle et professionnelle
    const aiPrompt = `
Tu es un assistant Campus France RDC bienveillant, professionnel et prÃ©cis.
RÃ©ponds de maniÃ¨re claire, concise et polie.
Tu peux utiliser des emojis lÃ©gers pour rendre la rÃ©ponse agrÃ©able (mais pas exagÃ©rÃ©s) et essauye 
d'ecourter du mieux que tu peux tes reponses.

Question de l'utilisateur :
"${message}"

RÃ©ponds en franÃ§ais, dans un ton humain et informatif.
`;

    const aiResponse = await fetch("https://api.groq.com/openai/v1/chat/completions", {
      method: "POST",
      headers: {
        "Authorization": `Bearer ${process.env.GROQ_API_KEY}`,
        "Content-Type": "application/json",
      },
      body: JSON.stringify({
        model: "llama-3.1-8b-instant",
        messages: [{ role: "user", content: aiPrompt }],
        temperature: 0.7,
      }),
    });

    const data = await aiResponse.json();
    const reply =
      data.choices?.[0]?.message?.content ||
      "Je nâ€™ai pas bien compris votre demande. Pouvez-vous reformuler ? ðŸ˜Š";

    res.json({ response: reply, redirect: false });

  } catch (e) {
    console.error("Erreur serveur :", e);
    res.status(500).json({ error: "Erreur serveur interne" });
  }
});

const PORT = process.env.PORT || 3000;
app.listen(PORT, () => console.log(`âœ… Serveur Groq IA lancÃ© sur le port ${PORT}`));