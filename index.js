import express from "express";
import fetch from "node-fetch";
import cors from "cors";
import { initializeApp, cert } from "firebase-admin/app";
import { getFirestore } from "firebase-admin/firestore";
import serviceAccount from "./serviceAccountKey.json" assert { type: "json" };

// ðŸ”¥ Initialisation Firebase Admin
initializeApp({
  credential: cert(serviceAccount),
});
const db = getFirestore();

const app = express();
app.use(cors());
app.use(express.json());

// ðŸ§  ROUTE IA / MESSAGERIE
app.post("/ask", async (req, res) => {
  try {
    const { message, userId, userName, role = "student" } = req.body;

    if (!message || message.trim() === "") {
      return res.status(400).json({ error: "Message vide" });
    }

    // ðŸ§© Sauvegarde du message de l'utilisateur
    const msgRef = db.collection("messages").doc(userId).collection("chat").doc();
    await msgRef.set({
      sender: role,
      message,
      timestamp: new Date(),
    });

    // ðŸ§  Ã‰tape 1 â€” DÃ©terminer si l'IA peut rÃ©pondre ou non
    const moderationPrompt = `
Tu es un assistant Campus France.
Analyse uniquement le contenu du message suivant : "${message}"

Si câ€™est une question gÃ©nÃ©rale (ex: procÃ©dure, visa, documents, frais, dÃ©lais, rendez-vous),
rÃ©ponds exactement par : IA_OK

Sinon, si câ€™est une question personnelle (ex: dossier individuel, compte bloquÃ©, paiement, problÃ¨me technique, retard...),
rÃ©ponds exactement par : AGENT

Ne donne aucune autre rÃ©ponse.
`;

    const modResponse = await fetch("https://api.groq.com/openai/v1/chat/completions", {
      method: "POST",
      headers: {
        "Authorization": `Bearer ${process.env.GROQ_API_KEY}`,
        "Content-Type": "application/json",
      },
      body: JSON.stringify({
        model: "llama-3.3-70b-versatile",
        messages: [{ role: "user", content: moderationPrompt }],
        temperature: 0.1,
      }),
    });

    const modData = await modResponse.json();
    const decision = modData.choices?.[0]?.message?.content?.trim() || "IA_OK";

    // ðŸš§ Ã‰tape 2 â€” Cas nÃ©cessitant un agent humain
    if (decision === "AGENT") {
      await msgRef.set(
        {
          response:
            "ðŸ“© Votre demande a Ã©tÃ© transmise Ã  un **agent Campus France** qui vous rÃ©pondra sous peu.",
          ai: false,
        },
        { merge: true }
      );

      return res.json({
        response:
          "ðŸ“© Votre demande semble spÃ©cifique Ã  votre dossier.\nElle a Ã©tÃ© transmise Ã  un **agent Campus France**.",
        redirect: true,
      });
    }

    // ðŸ¤– Ã‰tape 3 â€” RÃ©ponse automatique IA
    const aiPrompt = `
Tu es un assistant Campus France RDC bienveillant, professionnel et prÃ©cis.
RÃ©ponds de maniÃ¨re claire, concise et polie.
Tu peux utiliser quelques emojis lÃ©gers pour rendre la rÃ©ponse agrÃ©able.

Question de l'utilisateur :
"${message}"

RÃ©ponds en franÃ§ais.
`;

    const aiResponse = await fetch("https://api.groq.com/openai/v1/chat/completions", {
      method: "POST",
      headers: {
        "Authorization": `Bearer ${process.env.GROQ_API_KEY}`,
        "Content-Type": "application/json",
      },
      body: JSON.stringify({
        model: "llama-3.1-8b-instant",
        messages: [{ role: "user", content: aiPrompt }],
        temperature: 0.7,
      }),
    });

    const data = await aiResponse.json();
    const reply =
      data.choices?.[0]?.message?.content ||
      "Je nâ€™ai pas bien compris votre demande. Pouvez-vous reformuler ? ðŸ˜Š";

    // ðŸ’¾ Sauvegarde de la rÃ©ponse IA
    await msgRef.set(
      {
        response: reply,
        ai: true,
      },
      { merge: true }
    );

    res.json({ response: reply, redirect: false });
  } catch (e) {
    console.error("Erreur serveur :", e);
    res.status(500).json({ error: "Erreur serveur interne" });
  }
});

// ðŸ“‹ ROUTE ADMIN : liste des conversations actives
app.get("/conversations", async (req, res) => {
  try {
    const snapshot = await db.collection("messages").get();
    const users = snapshot.docs.map((doc) => ({
      userId: doc.id,
    }));
    res.json(users);
  } catch (e) {
    console.error("Erreur /conversations :", e);
    res.status(500).json({ error: "Erreur lors de la rÃ©cupÃ©ration des conversations" });
  }
});

const PORT = process.env.PORT || 3000;
app.listen(PORT, () => console.log(`âœ… Serveur Groq IA lancÃ© sur le port ${PORT}`));